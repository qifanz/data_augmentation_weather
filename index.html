<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
  <link href="css/custom.css" rel="stylesheet">
  <link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1 style='text-align: center'>Data augmentation - different weathers</h1> 
<p style="text-align: center; font-size: 20px; line-height: 1.5em;"><strong>Eric Gastineau, Yiliang Guo, Weiguang Huang, Qifan Zhang</strong></p>
<p style="text-align: center; font-size: 18px; line-height: 1.5em;">Fall 2019 Computer Vision: Class Project</p>
<p style="text-align: center; font-size: 18px; line-height: 1.5em;">Georgia Tech</p>
<hr>

<h2>Abstract</h2>
<p>
  The project will focus on applying computer vision techniques to effectively synthesize images with various types of weather conditions, such as rainy days, foggy days or snowy days. 
  The goal is to transform and synthesize images based on original images to effectively attain extra image data for deep learning model training. 
  Techniques considered to be applied include color mapping, image segmentation, texture modifications and other transformations.
</p>
<hr>

<h2>Project Proposal</h2>
<h3>Problem statement</h3>
<p>
  Deep learning techniques require a large amount of labelled data of good quality. Many widely recognized datasets are used to train models for autonomous vehicles like Cityscape, BDD, AppolloScape etc.. 
  Unfortunately, the majority of images from these datasets are taken during days with good weather. 
  As a result, most models trained on these datasets can work well in good weather conditions, but deteriorate significantly in other weather conditions, for example during a foggy day.</p>
<p>
  Our solution for this problem is to perform data augmentation before model training. 
  The goal of the project is to change the weather conditions in the images which are originally taken in good weather and already labelled, 
  and to produce labelled dataset with various weathers (with snow, smog, or rain etc.).
</p>
<div class='teaser'>
  <img class='teaser-img' src="img/teaser1.jpg">
</div>



<h3>Approach</h3>
<p>
  Data augmentation based on traditional computer vision techniques has been actively explored. 
  Simple techniques by cropping, rotating, and flipping has been proved with some effectiveness [1]. Image patching with randomly cropping is used to avoid overfitting[2]. 
</p>
<p>
  More sophisticated and recent deep learning techniques have also been developed in recent years to do data augmentation.
  For instance, GAN (generative adversarial network) or neural style transfer has been proposed to be used[1].
</p>
<P>
  On this project, we will develop and test methods based on traditional computer vision techniques but on a level further than cropping and patching. 
  Color mapping, image segmentation, texture modifications and other semantic transformations will be examined. 
</P>
<p>
  We will test the performance influence resulting from data augmentation by these techniques, and compare the performance to augmentation performed by deep learning techniques.
</p>

<h3>Experiments and results</h3>
<h4>
  Program code
</h4>
<p>
  For our computer vision techniques for data augmentation, we will use open source library such as OpenCV to implement image segmentation, 
  texture fusion etc, and further creatively adapt these techniques to our dataset augmentation.
</p>

<p>
  For the controlled group of deep learning techniques, we will use existing and publically available model codes to train on our datasets. 
  We may adapted available codes to fit in our purpose. 
</p>

<h4>
  Dataset
</h4>
<p>
  The goal is to perform data augmentation on benchmark datasets such as Berkeley Deep Drive (BDD)[3]. 
  We may also have to use extra images outside of a dedicated dataset since no publicly recognized dataset that contains sufficient image data with certain weather conditions, 
  for example foggy day,  to enable a comprehensive analysis.
</p>

<h4>
  Result validation
</h4>

<p>
  The results will first be validated by human vision. A synthesized/augmented image will receive a high rate if it canâ€™t be told from a group of other originally taken images. 
</p>

<p>
  In a computational way, the validation will be to train models with these synthesized/augmented images and test whether the models trained achieve a performance level same as or higher than trained with original images.
</p>

<hr>
<h2>
Reference
</h2>

<p>
  1.	Perez, Luis, and Jason Wang. "The effectiveness of data augmentation in image classification using deep learning."
   <i>arXiv preprint arXiv:1712.04621 (2017)</i>
</p>

<p>
  2.	Takahashi, Ryo, Takashi Matsubara, and Kuniaki Uehara. "Data augmentation using random image cropping and patching for deep cnns." 
  <i>IEEE Transactions on Circuits and Systems for Video Technology (2019)</i>
</p>

<p>
  3.	https://bdd-data.berkeley.edu/
</p>

</body></html>